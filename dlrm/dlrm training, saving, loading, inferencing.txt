python dlrm_s_pytorch.py --arch-sparse-feature-size=16 --arch-mlp-bot="13-512-256-64-16" --arch-mlp-top="512-256-1" --data-generation=dataset --data-set=kaggle --raw-data-file="meh/train.txt" --loss-function=bce --round-targets=True --learning-rate=0.1 --mini-batch-size=128 --print-freq=1024 --print-time

python dlrm_s_pytorch.py --nepochs=100 --data-generation=dataset --data-set=kaggle --raw-data-file="meh/train.txt"


python dlrm_s_pytorch.py --arch-sparse-feature-size=16 --arch-mlp-bot="13-512-256-64-16" --arch-mlp-top="512-256-1" --data-generation=dataset --data-set=kaggle --processed-data-file="meh/kaggleAdDisplayChallenge_processed.npz" --loss-function=bce --round-targets=True --learning-rate=0.1 --mini-batch-size=128 --print-freq=1024 --print-time



python dlrm_s_pytorch.py --arch-sparse-feature-size=16 --arch-mlp-bot="13-512-256-64-16" --arch-mlp-top="512-256-1" --data-generation=dataset --data-set=kaggle --processed-data-file="meh/kaggleAdDisplayChallenge_processed.npz" --loss-function=bce --round-targets=True --learning-rate=0.1 --mini-batch-size=392920 --print-freq=1024 --print-time --nepochs=10 --save-model="trainedModels/model.pt"





With test_freq (intervals that the model is checked for test accuracy):

python dlrm_s_pytorch.py --arch-sparse-feature-size=16 --arch-mlp-bot="13-512-256-64-16" --arch-mlp-top="512-256-1" --data-generation=dataset --data-set=kaggle --processed-data-file="meh/kaggleAdDisplayChallenge_processed.npz" --loss-function=bce --round-targets=True --learning-rate=0.1 --mini-batch-size=392920 --test-freq=2 --print-time --nepochs=4 --save-model="trainedModels/model.pt"




A sample run of the code, with a tiny model in debug mode

python dlrm_s_pytorch.py --mini-batch-size=2 --data-size=6 --debug-mode






MVP!


python dlrm_s_pytorch.py --arch-sparse-feature-size=16 --arch-mlp-bot="13-512-256-64-16" --arch-mlp-top="512-256-1" --data-generation=dataset --data-set=kaggle --processed-data-file="meh/kaggleAdDisplayChallenge_processed.npz" --loss-function=bce --round-targets=True --learning-rate=0.1 --mini-batch-size=39292 --test-freq=2 --print-time --nepochs=4 --save-model="trainedModels/model.pt"




Training the model and saving it

python dlrm_s_pytorch.py --arch-sparse-feature-size=16 --arch-mlp-bot="13-512-256-64-16" --arch-mlp-top="512-256-1" --data-generation=dataset --data-set=kaggle --processed-data-file="meh/kaggleAdDisplayChallenge_processed.npz" --loss-function=bce --round-targets=True --learning-rate=0.1 --mini-batch-size=188 --test-freq=209 --print-time --nepochs=20 --save-model="trainedModels/model.pt"





Loading the model just for inference:

python dlrm_s_pytorch.py --arch-sparse-feature-size=16 --arch-mlp-bot="13-512-256-64-16" --arch-mlp-top="512-256-1" --data-generation=dataset --data-set=kaggle --processed-data-file="meh/kaggleAdDisplayChallenge_processed.npz" --mini-batch-size=39292 --test-freq=2 --print-time --load-model="trainedModels/model.pt" --print-freq=1 --nepochs=10 --inference-only



Test:

python dlrm_s_pytorch.py --arch-sparse-feature-size=16 --arch-mlp-bot="13-512-256-64-16" --arch-mlp-top="512-256-1" --data-generation=dataset --data-set=kaggle --processed-data-file="meh/kaggleAdDisplayChallenge_processed.npz" --mini-batch-size=188 --load-model="trainedModels/model.pt" --print-freq=1 --nepochs=1 --inference-only





Inference with raw data file:
python dlrm_s_pytorch.py --arch-sparse-feature-size=16 --arch-mlp-bot="13-512-256-64-16" --arch-mlp-top="512-256-1" --data-generation=dataset --data-set=kaggle --raw-data-file="meh/test.txt" --load-model="trainedModels/model.pt" --print-freq=1 --nepochs=1 --inference-only









